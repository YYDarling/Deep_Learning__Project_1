{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YunDudali/TAMU_CSCE636_Project_1/blob/main/CSCE_636_Project_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TAMU - CSCE636 Project_1**"
      ],
      "metadata": {
        "id": "94xypjozDVf6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Requirement:**\n",
        "\n",
        "This project is on image classification for noisy MNIST dataset. When we add noise to images in the MNIST dataset, the digits in the images become more and more difficult for human to recognize. For example, the images here have increasingly large noise levels. However, interestingly, deep neural networks can still be trained to recognize them relatively well.\n",
        "\n",
        "Your task is to train a good hand-written-digit recognition classifier for the noisy images. Here are the train images and train labels. \n"
      ],
      "metadata": {
        "id": "r-AAmuFIDePS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Main Idea : **"
      ],
      "metadata": {
        "id": "ciQa2LxBoj65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Description**\n",
        "\n",
        "In this project, I firstly use matlab to process all the training images. The fist step is to plot out the histogram of all pixels at the edges. Because the edges from the clean MNIST data set are all \"0\"s so it can clearly reflect the distribution and types of the noise.\n",
        "\n",
        "After finishing the statistic process. A hypothesis cames out that for each pixel there's 90% possibility to add a uniform integer noise from 0 to 255. Under this assumption, a synthetic noisy image set is created and the pair between noisy and clean images can be set. The histogram are shown as below:\n",
        "![WeChat Screenshot_20220412154311.png](data:image/png;base64,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)\n",
        "\n",
        "By using these synthetic clean-noisy image pairs, An denoising autoencoder is trained. Since the noise is very strong, even the autoencoder can not perfectly recover the clean image. So in the final classification model, only the encoder part is used and the decoder part is given up. I froze the convolution layers and make the MLP part remains trainable in order to let the encoder learn more information about the original noisy images.\n",
        "\n",
        "A ResNet is connected after the Encoder to finish the classification problem, as a purpose of avoiding the overfitting, some synthetic noisy images are also added to the training set while the validation set uses only origional noisy images."
      ],
      "metadata": {
        "id": "lxnLdRuUaFkT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pU0zHPJPoUR5"
      },
      "outputs": [],
      "source": [
        "## This code block is used to train the Autoencoder\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import random\n",
        "\n",
        "##-----import data-----\n",
        "# Import the clean MNIST data set from the package\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_labels = np.reshape(train_labels, [-1])\n",
        "test_labels = np.reshape(test_labels, [-1])\n",
        "\n",
        "# Shuffle the clean data set\n",
        "shuffle_index = np.random.permutation(train_images.shape[0])\n",
        "train_images = train_images[shuffle_index]\n",
        "train_labels = train_labels[shuffle_index]\n",
        "shuffle_index = np.random.permutation(test_images.shape[0])\n",
        "test_images = test_images[shuffle_index]\n",
        "test_labels = test_labels[shuffle_index]\n",
        "\n",
        "# Add noise according to my assumption from the statistical information given by MATLAB\n",
        "x_train_noisy = np.mod(train_images + np.random.binomial(n=1, p=0.9, size=train_images.shape) * np.random.randint(low=1, high=256, size=train_images.shape), 255)\n",
        "x_train_noisy = np.clip(x_train_noisy, 0, 255) / 255\n",
        "x_test_noisy = np.mod(test_images + np.random.binomial(n=1, p=0.9, size=test_images.shape) * np.random.randint(low=1, high=256, size=test_images.shape), 255)\n",
        "x_test_noisy = np.clip(x_test_noisy, 0, 255) / 255\n",
        "\n",
        "##-----Autoencoder Model-----\n",
        "inputs = keras.Input(shape=(28, 28, 1))\n",
        "x = inputs\n",
        "# Encoder, Contains 3 CONV block, for each block, there are two conv-averagepooling layers.\n",
        "for depth in [16, 16, 32]:\n",
        "    x = layers.Conv2D(filters=depth, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.AveragePooling2D(pool_size=2, strides=1, padding=\"same\")(x)\n",
        "    x = layers.Conv2D(filters=depth, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.AveragePooling2D(pool_size=2, strides=1, padding=\"same\")(x)\n",
        "\n",
        "# After the 2D convolution, a Dense layer is added to compress the encoded information\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(512, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(28*28*32, activation=\"relu\")(x)\n",
        "x = layers.Reshape([28, 28, 32])(x)\n",
        "\n",
        "# Decoder, contaions 3 CONV block, for each block, 3 convolution transpose layers are used. The Decoder is used to filter out the noise\n",
        "for depth in [32, 16, 16]:\n",
        "    x = layers.Conv2DTranspose(filters=depth, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2DTranspose(filters=depth, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\")(x)\n",
        "# The lasy CONV layer is used to recover the data back into the correct shape\n",
        "x = layers.Conv2D(filters=1, kernel_size=3, strides=1, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "\n",
        "\n",
        "model = keras.Model(inputs, x)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\")\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"./filter_test_new_deep_v1.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "history = model.fit(x_train_noisy, train_images / 255, epochs=150, shuffle=True, batch_size=512, callbacks=callbacks,\n",
        "                validation_data=(x_test_noisy, test_images / 255), shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This block is used to train the classification problem\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import pandas as pd\n",
        "\n",
        "##-----import data-----\n",
        "# Firstly, import the original noisy data from the project\n",
        "train_data_path = './636_project1_train_images'\n",
        "train_label_path = './636_project1_train_labels'\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "train_data = pickle.load(open(train_data_path, 'rb'))\n",
        "train_label = pickle.load(open(train_label_path, 'rb'))\n",
        "train_data = train_data.numpy() / 255\n",
        "train_label = train_label.numpy()\n",
        "# shuffle the original data set and split it into training and validation data set\n",
        "shuffle_index = np.random.permutation(train_data.shape[0])\n",
        "train_data = train_data[shuffle_index]\n",
        "train_label = train_label[shuffle_index]\n",
        "val_data = train_data[0:20000]\n",
        "val_label = train_label[0:20000]\n",
        "train_data = train_data[20000:]\n",
        "train_label = train_label[20000:]\n",
        "\n",
        "# import clean MNIST data set and shuffle it\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_labels = np.reshape(train_labels, [-1])\n",
        "test_labels = np.reshape(test_labels, [-1])\n",
        "shuffle_index = np.random.permutation(train_images.shape[0])\n",
        "train_images = train_images[shuffle_index]\n",
        "train_labels = train_labels[shuffle_index]\n",
        "shuffle_index = np.random.permutation(test_images.shape[0])\n",
        "test_images = test_images[shuffle_index]\n",
        "test_labels = test_labels[shuffle_index]\n",
        "\n",
        "# Add noise to the clean MNIST data according to my assumption for the noise \n",
        "x_train_noisy = np.mod(train_images + np.random.binomial(n=1, p=0.9, size=train_images.shape) * np.random.randint(low=1, high=256, size=train_images.shape), 255)\n",
        "x_train_noisy = np.clip(x_train_noisy, 0, 255) / 255\n",
        "x_test_noisy = np.mod(test_images + np.random.binomial(n=1, p=0.9, size=test_images.shape) * np.random.randint(low=1, high=256, size=test_images.shape), 255)\n",
        "x_test_noisy = np.clip(x_test_noisy, 0, 255) / 255\n",
        "\n",
        "# combine the original noisy image set from the project and my synthetic noisy images to avoid early overfitting issue.\n",
        "train_data = np.concatenate((train_data, x_train_noisy), axis=0)\n",
        "train_label = np.concatenate((train_label, train_labels), axis=0)\n",
        "\n",
        "##-----Model for Classification------\n",
        "# First, import the autoencoder trained before. But just the encoder part and the Dense layers are used. The decoder part is aborted\n",
        "autoencoder = keras.models.load_model(\"./filter_test_new_deep_v1.keras\")\n",
        "autoencoder.trainable = False\n",
        "new_model = keras.Sequential()\n",
        "for ix in range(0, 17 + 1):\n",
        "    curr_layer = autoencoder.get_layer(index=ix)\n",
        "    new_model.add(curr_layer)\n",
        "# Set the Dense layers to be trainable, in order to learn more information from the original noisy dataset.\n",
        "new_model.trainable = True\n",
        "for layer in new_model.layers[:-4]:\n",
        "    layer.trainable = False\n",
        "new_model.summary()\n",
        "\n",
        "# The Squeeze-Extraction Net is not usefull in this project, so this part is abandoned\n",
        "def SENet(input, depth):\n",
        "    x = layers.GlobalAveragePooling2D()(input)\n",
        "    x = layers.Reshape([1, 1, depth])(x)\n",
        "    x = layers.Dense(int(depth / 2), activation=\"relu\")(x)\n",
        "    x = layers.Dense(depth, activation=\"sigmoid\")(x)\n",
        "    return x\n",
        "\n",
        "# The classification model with encoder embeded. The whole structure is: Input -> encoder (pretrained) -> ResNet\n",
        "inputs = keras.Input(shape=(28, 28, 1))\n",
        "x = new_model(inputs) # Encoder part (pretrained, but the Dense layers are trainable)\n",
        "x = layers.Reshape([28, 28, 32])(x)\n",
        "for depth in [32, 32, 32, 64, 64]:  # Simple ResNet\n",
        "    res = x\n",
        "\n",
        "    unique_id = random.randint(1, 99999999)\n",
        "    x = layers.Conv2D(filters=depth, kernel_size=3, strides=1, padding='same', activation='relu', name=\"my_layer_name_{}\".format(unique_id))(x)\n",
        "    # w1 = SENet(input=x, depth=depth)\n",
        "    # x = layers.multiply([x, w1])\n",
        "    x = layers.MaxPooling2D(pool_size=2, strides=1, padding='same')(x)\n",
        "\n",
        "    unique_id = random.randint(1, 99999999)\n",
        "    x = layers.Conv2D(filters=depth, kernel_size=3, strides=1, padding='same', activation='relu', name=\"my_layer_name_{}\".format(unique_id))(x)\n",
        "    # w2 = SENet(input=x, depth=depth)\n",
        "    # x = layers.multiply([x, w2])\n",
        "    x = layers.MaxPooling2D(pool_size=2, strides=1, padding='same')(x)\n",
        "\n",
        "    unique_id = random.randint(1, 99999999)\n",
        "    res = layers.Conv2D(filters=depth, kernel_size=1, strides=1, padding='same', activation='tanh', name=\"my_layer_name_{}\".format(unique_id))(res)\n",
        "    # w3 = SENet(input=res, depth=depth)\n",
        "    # res = layers.multiply([res, w3])\n",
        "\n",
        "    x = layers.add([x, res])\n",
        "    # x = layers.BatchNormalization()(x)\n",
        "\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "# x = layers.Dense(64, activation='relu')(x)\n",
        "unique_id = random.randint(1, 99999999)\n",
        "x = layers.Dense(10, activation='softmax', name=\"my_layer_name_{}\".format(unique_id))(x)\n",
        "\n",
        "model = keras.Model(inputs, x)\n",
        "model.summary()\n",
        "\n",
        "shuffle_index = np.random.permutation(train_data.shape[0])\n",
        "train_data = train_data[shuffle_index]\n",
        "train_label = train_label[shuffle_index]\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"./project_2.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "history = model.fit(train_data, train_label, epochs=300, callbacks=callbacks, batch_size=512,\n",
        "                    validation_data=(val_data, val_label), shuffle=True)\n"
      ],
      "metadata": {
        "id": "BYzTYs-9ld7n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}